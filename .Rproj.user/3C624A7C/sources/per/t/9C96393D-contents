---
title: "Problem Set 04"
subtitle: "AQMSS II"
author: "Polikanov Stepan"
format:
  pdf:
    code_download: true
    fontsize: 11pt
    highlight-style: kate
    fig-width: 10
    fig-height: 6
    include-in-header:
      - text: |
          \addtokomafont{disposition}{\rmfamily} 
          \AddToHook{env/Highlighting/begin}{\scriptsize} 
          \usepackage{float} 
embed-resources: true
execute: 
  echo: true
  warning: false
  error: false
  message: false
---

```{r}
#| label: setup chunk

  ## Required packages
  packages <- c("here", "haven", "readxl",
                "tidyverse", "Hmisc", 
                "tidymodels", "marginaleffects")
    
  ## Install packages not yet installed
  installed_packages <- packages %in% rownames(installed.packages())
    if (any(installed_packages == FALSE)) {
      install.packages(packages[!installed_packages])
    }
    
  ## Load package
  invisible(lapply(packages, library, character.only = TRUE))
  
  # Define global functions

  ## Fitting stargazer onto the page
  resizebox.stargazer = function(..., tab.width = "!", tab.height = "!")
      {
    require(stringr) 
    res = capture.output(stargazer::stargazer(...))
    tab.width = tab.width
    tab.height = tab.height
    res = prepend(res, "}", before = length(res))
  
    res = c(res[1:str_which(res, "^\\\\begin\\{tabular\\}.*")-1],
        paste0("\\resizebox*{",tab.width,"}{",tab.height,"}{%"),
        res[str_which(res, "^\\\\begin\\{tabular\\}.*"):length(res)]
        )
    cat(res, sep = "\n")
  }

options(scipen = 999)
```

\section{Maximum Likelihood}

\subsection{a}

Likelihood function gives us the probability to observe the data given some parameter $\theta$. The function is defined as $L(\theta|X)$. The $\theta$ is the data-generating process (for example for fair coin-flipping the DGP is pure chance $\theta = 0.5$). Inference in this context means finding $\theta$ or an unbiased estimate of it, $\hat\theta$. 

\subsection{b}

The idea is to maximize the likelihood function to obtain $\hat\theta$ that make the data (given the specific model assumptions) most likely to be observed. 

$$\hat\theta_{MLE} = \max_{\theta} L(\theta|X)$$

\subsection{c}

$$P(X|\theta) = \Pi^N_{i = 1} p(x_i|\theta) = \Pi^N_{i = 1} \theta^{x_i}(1 - \theta)^{1 - x_i}$$

\subsection{d}

To avoid working with products we can take the logarithm and go to sums:

$$logP(X|\theta) = \sum^N_{i = 1} log \text{ }p(x_i|\theta) = \sum^N_{i = 1} (x_i log \text{ } \theta + (1 - x_i) log \text{} (1 - \theta))$$

To maximize the likelihood function we take the derivative. F.O.C:

$$\frac{\partial \text{ } log \text{ } P(X|\theta)}{\partial \theta} = \sum^N_{i = 1} \frac{x_i}{\theta} + \frac{1 - x_i}{1 - \theta} = 0$$

$$(1 - \theta)\sum^N_{i = 1} x_i + \theta \sum^N_{i = 1} x_i - \theta N = 0$$
$$\sum^N_{i = 1}x_i = \theta N$$
$$\hat\theta = \frac{1}{N}\sum^N_{i = 1}x_i$$

$$\hat\theta = \frac{1}{13} * 7 = \frac{7}{13}$$

\newpage

\section{Logistic models}

\subsection{a}

```{r}
#| label: data
#| cache: true
#| cache-lazy: false

gss <- read_dta(here("scripts", "data", "gss7222_r3.dta"))
milspend <- read_excel(here("scripts", "data", 
                            "API_MS.MIL.XPND.CD_DS2_en_excel_v2_43586.xls"),
                       skip = 2)
```

I will be looking at people who are saying that "the government spends \emph{too much} on the military, armaments and defense". Non-response appears in two ways - not applicable, i.e people who were not asked this question (coded NA(i)) and people who answered "Don't know" (coded NA(d)). I delete all observations with the former and retain the latter. It goes into the group that didn't respond "Too much", so they are the part of the group coded 0 in a dummy.

```{r}
#| label: isolate data
#| cache: true

gss_select <- gss |> 
  select(year, id, sex, age, educ, race, natarms) |> 
  filter(year != 1972, na_tag(natarms) == "d" | !is.na(natarms)) |> 
  mutate(natarms = if_else(is.na(natarms) & na_tag(natarms) == "d", 4, natarms),
         natarms_much = if_else(natarms == 3, 1, 0))

milspend_select <- milspend |> 
  filter(`Country Name` == "United States") |> 
  pivot_longer(cols = 5:67, names_to = "year", values_to = "spent") |> 
  select(year, spent) |> 
  mutate(year = as.numeric(year))
```

\subsection{b}

```{r}
#| label: plot

gss_select |> 
  group_by(year) |> 
  dplyr::summarize(mean_nam = binconf(x = sum(natarms_much == 1), n = length(natarms_much))[, 1],
                   lower = binconf(x = sum(natarms_much == 1), n = length(natarms_much))[, 2],
                   upper = binconf(x = sum(natarms_much == 1), n = length(natarms_much))[, 3]) |> 
  left_join(milspend_select, by = "year") |> 
  ggplot(aes(x = year, ymin = lower, ymax = upper)) +
    geom_point(aes(y = mean_nam)) +
    geom_line(aes(y = spent/1000000000000, x = year), color = "red") +
    geom_errorbar(aes(ymin = lower, ymax = upper)) + 
    scale_x_continuous(limits = c(1972, 2023),
                       breaks = seq(1974, 2022, 2)) +
    scale_y_continuous(limits = c(0, 0.9),
                       breaks = seq(0, 0.9, 0.1), 
                       sec.axis = sec_axis(trans = ~ . * 1000, 
                                           name = "Military expenditure, bil USD\n",
                                           breaks = seq(0, 900, 100),
                                           labels = 
                                             scales::label_currency(suffix = " bil"))) +
    labs(x = "", y = "% thinking spending too much\n",
         title = "Share of people thinking the gov't spends too much on arms",
         subtitle = "Red line indicates actual military expenditure") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

\subsection{c}

```{r}
#| label: logistic regression

models <- gss_select |> 
  filter(race != 3) |> 
  mutate(sex = factor(sex, levels = c(1, 2), labels = c("Male", "Female")),
         race = factor(race, levels = c(1, 2), labels = c("White", "Black"))) |> 
  group_by(year) |> 
  nest() |> 
  mutate(models = map(data, 
                      function(df) tidy(glm(
                        natarms_much ~ sex + age + educ + race, data = df,
                        family = binomial("logit")), 
                        conf.int = T))) |> 
  select(-data) |> 
  unnest(cols = c(models)) |> 
  filter(term != "(Intercept)") |> 
  mutate(term = factor(term,
                       levels = c("sexFemale", "age", "educ", "raceBlack"),
                       labels = c("Female", "Age", "Education", 
                                  "Black (ref white)")),
         sig = factor(if_else(0 >= conf.low & 0 <= conf.high, 0, 1), 
                      levels = c(0, 1), labels = c("No", "Yes")))

  ggplot(models, aes(x = estimate, xmin = conf.low, xmax = conf.high, y = term,
             color = sig)) +
    geom_point(size = .5) +
    geom_errorbarh(linewidth = .15) +
    geom_vline(xintercept = 0, lty = 2) +
    scale_color_manual(values = c("#DF2E38", "#5D9C59")) +
    scale_x_continuous(limits = c(-0.5, 1),
                       breaks = seq(-0.5, 1, 0.5)) +
    labs(x = "Estimates of the socio-demographic variables", y = NULL,
         color = "Significant?",
         title = "Coefficient plot for the logistic model",
         subtitle = "Predicting \nDropped race - other due to singular fits in the earlier years"
    ) +
    facet_wrap(~ year) + 
    theme_bw() +
    theme(legend.position = "bottom")

```

\subsection{d}

I first plot relative risk ratios for all years.

```{r}
#| label: education and arms

models |> 
  filter(term == "Education") |> 
  ggplot(aes(x = year, y = exp(estimate) - 1, ymin = exp(conf.low) - 1, ymax = exp(conf.high) - 1)) +
    geom_point() +
    geom_line(linewidth = 0.15) +
    geom_errorbar(aes(color = sig)) +
    scale_color_manual(values = c("#DF2E38", "#5D9C59")) +
    scale_y_continuous(labels = scales::label_number(prefix = "+ ", scale = 100, suffix = "%"),
                       breaks = seq(0, 0.3, 0.05)) +
    scale_x_continuous(breaks = seq(1973, 2023, 2)) +
    labs(title = 
           "How much each additional year of schooling affects thinking that gov't overspends on arms?",
         x = NULL, 
         y = "Change in relative risk of people thinking gov't overspends\n",
         color = "Significant?") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

For substantive interpretation of probabilities I turn my attention to one if the greatest security challenges in US history - the 9/11. In particular I compare simulated quantities of interest in 2000 and 2002 - before and after the attack and look at the effects of education. The expectation is clear: there should be a location change of the education - everyone should start wanting more money for defense purposes - and some of the differences between more and less educated should also even out, as the shock and outrage was national and very broad.

```{r}
#| label: nine eleven
m2000 = glm(natarms_much ~ sex + age + educ + race, 
         family = "binomial", data = gss_select, subset = year == 2000)
m2002 = glm(natarms_much ~ sex + age + educ + race, family = "binomial", 
         data = gss_select, subset = year == 2002)

plot_predictions(m2000, condition = "educ") +
  scale_y_continuous(limits = c(0, 0.45),
                     breaks = seq(0, 0.45, 0.05)) +
  labs(title = 
         "Years of education and probability to think gov't is overspending on military",
       subtitle = "For the year 2000",
       x = "\nYears of Education",
       y = "Pr\n") +
  theme_bw()

plot_predictions(m2002, condition = "educ") +
    scale_y_continuous(limits = c(0, 0.45),
                     breaks = seq(0, 0.45, 0.05)) +
  
    labs(title = 
         "Years of education and probability to think gov't is overspending on military",
       subtitle = "For the year 2002",
       x = "\nYears of Education",
       y = "Pr\n") +
  theme_bw()

```
Indeed the theoretical expectations are confirmed - the share of those answering "Too much" goes down in 2002 and doesn't exceed 0.3 - while it was maxed at 0.35 two years prior. The differences between the higher and lower ends of the educational attainment spectrum also diminish - but not to any significant extent.

\subsection{e}

To properly investigate the attitudes towards military spending it is, as shown above, necessary to focus on specific historical events that lead to sharp changes in public opinion. This allows for causal identification. 

On the other hand, binary variables are probably not the way to go - the distinction between thinking that the government is spending enough or not enough is also conceptually significant - and tied to political attitudes. On the subject of political attitudes we can expect a gap between democrats and republicans - yet there are two mechanisms - the first being that democrats on average probably are more likely to have pacifist views - and the second being more likely to supported a "maximal" state design, resulting in more spending in all categories. 

Moreover, we will need to control for political knowledge - as ways of budget allocation might not be crystal clear, in particular for the lower end of the educational scale.
